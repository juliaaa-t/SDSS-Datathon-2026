{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Business Case Description"
      ],
      "metadata": {
        "id": "ER4_FQHS_5Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toronto is one of the most expensive cities in Canada, with individuals facing rising rent, tuition, and basic living expenses. Due to this, many Canadians are concerned about their financial well-being."
      ],
      "metadata": {
        "id": "bwg6PZDD__Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "zCaxFFi1AlSY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brm_h3qQ_qoG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "Lw40U3eoJyIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"personal_finance_dataset.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name=\"datathon_finance\", engine=\"openpyxl\")\n",
        "df = df.drop(columns=[\"PATTSITC\", \"PATTSKP\", \"PEFATINC\", \"PFTENUR\", \"PLFFPTME\", \"PNBEARG\"])\n",
        "df = df.drop_duplicates()\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "j-EA6rlEC8--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source Code"
      ],
      "metadata": {
        "id": "ixAwJrZjJ_jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn xgboost shap openpyxl"
      ],
      "metadata": {
        "id": "Oq6sJ1tNVfTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import shap"
      ],
      "metadata": {
        "id": "ChbmcRiVVgFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1. Load Excel Data\n",
        "# -----------------------------\n",
        "df = pd.read_excel(\"your_file.xlsx\")\n",
        "\n",
        "X = df[[\n",
        "    \"Net Debt\",\n",
        "    \"Net Worth\",\n",
        "    \"TFSA Balance\",\n",
        "    \"Bank Deposit\",\n",
        "    \"After-Tax Income\"\n",
        "]]\n",
        "\n",
        "y = df[\"stress\"]  # Binary outcome (1 = stress, 0 = stable)"
      ],
      "metadata": {
        "id": "dS9KI-DfVqWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2. Train/Test Split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "DBfszt7uWTTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 3. Define Base Models\n",
        "# -----------------------------\n",
        "\n",
        "# Logistic Regression (Elastic Net)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "log_model = LogisticRegression(\n",
        "    penalty=\"elasticnet\",\n",
        "    solver=\"saga\",\n",
        "    l1_ratio=0.5,\n",
        "    max_iter=5000\n",
        ")\n",
        "\n",
        "# Gradient Boosting (XGBoost)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jc4QIYdvWVQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4. Stacking Model\n",
        "# -----------------------------\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        (\"logistic\", log_model),\n",
        "        (\"xgb\", xgb_model)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "stack_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8N3c2RbIWXay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 5. Evaluate\n",
        "# -----------------------------\n",
        "\n",
        "probs_stack = stack_model.predict_proba(X_test)[:, 1]\n",
        "auc_stack = roc_auc_score(y_test, probs_stack)\n",
        "\n",
        "print(\"Stacked Model AUC:\", auc_stack)"
      ],
      "metadata": {
        "id": "OBKm8oO-WZgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Interpretation"
      ],
      "metadata": {
        "id": "8-5s7HjdWgmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Coefficient\": log_model.coef_[0],\n",
        "    \"Odds_Ratio\": np.exp(log_model.coef_[0])\n",
        "}).sort_values(by=\"Odds_Ratio\", ascending=False)\n",
        "\n",
        "print(coefficients)"
      ],
      "metadata": {
        "id": "dknJK6_kWlFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost + SHAP (Best Variable Ranking) Interpretation"
      ],
      "metadata": {
        "id": "OraWwoQ3WoRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "shap.summary_plot(shap_values, X_train)"
      ],
      "metadata": {
        "id": "tmjFYenJWo69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priority 3 Weights"
      ],
      "metadata": {
        "id": "gKP932WoXFk2"
      }
    }
  ]
}