{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Business Case Description"
      ],
      "metadata": {
        "id": "ER4_FQHS_5Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toronto is one of the most expensive cities in Canada, with individuals facing rising rent, tuition, and basic living expenses. Due to this, many Canadians are concerned about their financial well-being."
      ],
      "metadata": {
        "id": "bwg6PZDD__Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source Code"
      ],
      "metadata": {
        "id": "ixAwJrZjJ_jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn xgboost shap openpyxl"
      ],
      "metadata": {
        "id": "Oq6sJ1tNVfTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c862a6fe-20c3-4dfb-c8e3-64b70ff8c6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.3)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (26.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import shap"
      ],
      "metadata": {
        "id": "ChbmcRiVVgFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load Excel Data\n",
        "# -----------------------------\n",
        "\n",
        "file_path = \"personal_finance_dataset.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name=\"datathon_finance\", engine=\"openpyxl\")\n",
        "df = df.drop(columns=[\"PATTSITC\", \"PATTSKP\", \"PFTENUR\", \"PLFFPTME\", \"PNBEARG\"])\n",
        "df = df.drop_duplicates()\n",
        "df = df.rename(columns={\n",
        "    \"PAGEMIEG\": \"Age Group\",\n",
        "    \"PATTCRU\": \"Credit Card Payment\",\n",
        "    \"PWAPRVAL\": \"Home Value\",\n",
        "    \"PWASTDEP\": \"Bank Deposits\",\n",
        "    \"PWATFS\": \"TFSA Balance\",\n",
        "    \"PWDPRMOR\": \"Mortgage Debt\",\n",
        "    \"PWDSLOAN\": \"Student Loan Debt\",\n",
        "    \"PWDSTCRD\": \"Credit Card Debt\",\n",
        "    \"PWDSTLOC\": \"Line of Credit Debt\",\n",
        "    \"PWNETWPG\": \"Net Worth\",\n",
        "    \"PPVRES\": \"Province\",\n",
        "    \"PFMTYPG\": \"Family Type\",\n",
        "    \"PEDUCMIE\": \"Education Level\",\n",
        "    \"PEFATINC\": \"After-Tax Income\"\n",
        "})\n",
        "debt_cols = [\"Mortgage Debt\", \"Line of Credit Debt\", \"Credit Card Debt\", \"Student Loan Debt\"]\n",
        "df[\"Total Debt\"] = df[debt_cols].sum(axis=1)\n",
        "cal_cols = [\"Net Worth\", \"Total Debt\"]\n",
        "df[\"ratio\"] = df[\"Total Debt\"]/(df[\"Net Worth\"] + 0.00000001)\n",
        "df = df.drop(columns=[\"Education Level\", \"Family Type\", \"Province\",\n",
        "                      \"Line of Credit Debt\", \"Credit Card Debt\",\n",
        "                      \"Student Loan Debt\",\n",
        "                      \"Mortgage Debt\", \"Line of Credit Debt\",\n",
        "                      \"Credit Card Debt\", \"Home Value\", \"Age Group\", \"Credit Card Payment\"])\n",
        "\n",
        "features = [\"After-Tax Income\",\n",
        "    \"Bank Deposits\",\n",
        "    \"TFSA Balance\",\n",
        "    \"Net Worth\",\n",
        "    \"Total Debt\"]\n",
        "\n",
        "\n",
        "Q1 = df[features].quantile(0.25)\n",
        "Q3 = df[features].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "mask = ~((df[features] < lower_bound) | (df[features] > upper_bound)).any(axis=1)\n",
        "df = df[mask]\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": df[features].mean(),\n",
        "    \"Median\": df[features].median(),\n",
        "    \"Mode\": df[features].mode().iloc[0]\n",
        "})\n",
        "print(summary)\n",
        "\n",
        "import numpy as np\n",
        "for col in features:\n",
        "    df[col] = np.log1p(df[col])\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df[\"TFSA Balance\"], bins=50, kde=True)\n",
        "plt.xlabel(\"Bank Deposits\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"TFSA Balance Distribution\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X = df[[\n",
        "    \"Net Debt\",\n",
        "    \"Net Worth\",\n",
        "    \"TFSA Balance\",\n",
        "    \"Bank Deposit\",\n",
        "    \"After-Tax Income\"\n",
        "]]\n",
        "\n",
        "y = df[\"stress\"]  # Binary outcome (1 = stress, 0 = stable)"
      ],
      "metadata": {
        "id": "ZoEQNya0sbLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2. Train/Test Split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "DBfszt7uWTTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 3. Define Base Models\n",
        "# -----------------------------\n",
        "\n",
        "# Logistic Regression (Elastic Net)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "log_model = LogisticRegression(\n",
        "    penalty=\"elasticnet\",\n",
        "    solver=\"saga\",\n",
        "    l1_ratio=0.5,\n",
        "    max_iter=5000\n",
        ")\n",
        "\n",
        "# Gradient Boosting (XGBoost)\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jc4QIYdvWVQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4. Stacking Model\n",
        "# -----------------------------\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        (\"logistic\", log_model),\n",
        "        (\"xgb\", xgb_model)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "stack_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8N3c2RbIWXay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 5. Evaluate\n",
        "# -----------------------------\n",
        "\n",
        "probs_stack = stack_model.predict_proba(X_test)[:, 1]\n",
        "auc_stack = roc_auc_score(y_test, probs_stack)\n",
        "\n",
        "print(\"Stacked Model AUC:\", auc_stack)"
      ],
      "metadata": {
        "id": "OBKm8oO-WZgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression Interpretation"
      ],
      "metadata": {
        "id": "8-5s7HjdWgmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    \"Variable\": X.columns,\n",
        "    \"Coefficient\": log_model.coef_[0],\n",
        "    \"Odds_Ratio\": np.exp(log_model.coef_[0])\n",
        "}).sort_values(by=\"Odds_Ratio\", ascending=False)\n",
        "\n",
        "print(coefficients)"
      ],
      "metadata": {
        "id": "dknJK6_kWlFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost + SHAP (Best Variable Ranking) Interpretation"
      ],
      "metadata": {
        "id": "OraWwoQ3WoRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "shap.summary_plot(shap_values, X_train)"
      ],
      "metadata": {
        "id": "tmjFYenJWo69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}